{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ENUAjkyFTL1N"
   },
   "source": [
    "### DataFrame Transformations\n",
    "---------\n",
    "The material in this notebook was extracted from\n",
    "* Spark The Definitive Guide Big Data Processing Made Simple (2018)\n",
    "---------\n",
    "\n",
    "When working with individual DataFrames, there are some fundamental objectives. These break down into several core operations:\n",
    "\n",
    "- Add rows or columns\n",
    "- Remove rows or columns\n",
    "- Transform rows into columns (or vice versa)\n",
    "- Sort data by values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9kiugR2kTL1Q"
   },
   "source": [
    "#### Creating DataFrames\n",
    "\n",
    "We can create DataFrames from raw data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))\n",
    "data_path = os.path.join('..', '..', '..', 'FuentesDeDatos', 'classes', 'class_notes', 'class_18', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 537,
     "status": "error",
     "timestamp": 1582667121787,
     "user": {
      "displayName": "INAKI CARRANZA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBzUDe9EIZKTePcre9-f_eslrQQ_uq5ta5GplLi=s64",
      "userId": "03193546701798218263"
     },
     "user_tz": 360
    },
    "id": "sTC-CS6PTL1S",
    "outputId": "991cb2ec-2180-4763-f753-bca132c36a40"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('YEAR', 'int'),\n",
       " ('MONTH', 'int'),\n",
       " ('DAY', 'int'),\n",
       " ('DAY_OF_WEEK', 'int'),\n",
       " ('AIRLINE', 'string'),\n",
       " ('FLIGHT_NUMBER', 'int'),\n",
       " ('TAIL_NUMBER', 'string'),\n",
       " ('ORIGIN_AIRPORT', 'string'),\n",
       " ('DESTINATION_AIRPORT', 'string'),\n",
       " ('SCHEDULED_DEPARTURE', 'int'),\n",
       " ('DEPARTURE_TIME', 'int'),\n",
       " ('DEPARTURE_DELAY', 'int'),\n",
       " ('TAXI_OUT', 'int'),\n",
       " ('WHEELS_OFF', 'int'),\n",
       " ('SCHEDULED_TIME', 'int'),\n",
       " ('ELAPSED_TIME', 'int'),\n",
       " ('AIR_TIME', 'int'),\n",
       " ('DISTANCE', 'int'),\n",
       " ('WHEELS_ON', 'int'),\n",
       " ('TAXI_IN', 'int'),\n",
       " ('SCHEDULED_ARRIVAL', 'int'),\n",
       " ('ARRIVAL_TIME', 'int'),\n",
       " ('ARRIVAL_DELAY', 'int'),\n",
       " ('DIVERTED', 'int'),\n",
       " ('CANCELLED', 'int'),\n",
       " ('CANCELLATION_REASON', 'string'),\n",
       " ('AIR_SYSTEM_DELAY', 'int'),\n",
       " ('SECURITY_DELAY', 'int'),\n",
       " ('AIRLINE_DELAY', 'int'),\n",
       " ('LATE_AIRCRAFT_DELAY', 'int'),\n",
       " ('WEATHER_DELAY', 'int')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spark.read.csv(./data/flights, sep=',', header=True, inferSchema=True)\n",
    "df = (spark.read\n",
    ".format('csv')\n",
    ".option('header', True)\n",
    ".option('inferSchema', True)\n",
    ".load(os.path.join(data_path, 'flights.csv')))\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 17:21:03 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
      "|YEAR|MONTH|DAY|DAY_OF_WEEK|AIRLINE|FLIGHT_NUMBER|TAIL_NUMBER|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|DEPARTURE_TIME|DEPARTURE_DELAY|TAXI_OUT|WHEELS_OFF|SCHEDULED_TIME|ELAPSED_TIME|AIR_TIME|DISTANCE|WHEELS_ON|TAXI_IN|SCHEDULED_ARRIVAL|ARRIVAL_TIME|ARRIVAL_DELAY|DIVERTED|CANCELLED|CANCELLATION_REASON|AIR_SYSTEM_DELAY|SECURITY_DELAY|AIRLINE_DELAY|LATE_AIRCRAFT_DELAY|WEATHER_DELAY|\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
      "|2015|1    |1  |4          |AS     |98           |N407AS     |ANC           |SEA                |5                  |2354          |-11            |21      |15        |205           |194         |169     |1448    |404      |4      |430              |408         |-22          |0       |0        |null               |null            |null          |null         |null               |null         |\n",
      "|2015|1    |1  |4          |AA     |2336         |N3KUAA     |LAX           |PBI                |10                 |2             |-8             |12      |14        |280           |279         |263     |2330    |737      |4      |750              |741         |-9           |0       |0        |null               |null            |null          |null         |null               |null         |\n",
      "|2015|1    |1  |4          |US     |840          |N171US     |SFO           |CLT                |20                 |18            |-2             |16      |34        |286           |293         |266     |2296    |800      |11     |806              |811         |5            |0       |0        |null               |null            |null          |null         |null               |null         |\n",
      "|2015|1    |1  |4          |AA     |258          |N3HYAA     |LAX           |MIA                |20                 |15            |-5             |15      |30        |285           |281         |258     |2342    |748      |8      |805              |756         |-9           |0       |0        |null               |null            |null          |null         |null               |null         |\n",
      "|2015|1    |1  |4          |AS     |135          |N527AS     |SEA           |ANC                |25                 |24            |-1             |11      |35        |235           |215         |199     |1448    |254      |5      |320              |259         |-21          |0       |0        |null               |null            |null          |null         |null               |null         |\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m (df\n\u001b[0;32m----> 2\u001b[0m  \u001b[38;5;241m.\u001b[39mselect(\u001b[43mF\u001b[49m\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYEAR\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m), F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMONTH\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m), F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDAY\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      3\u001b[0m  \u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m, F\u001b[38;5;241m.\u001b[39mconcat(F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m), F\u001b[38;5;241m.\u001b[39mlit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m), F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m), F\u001b[38;5;241m.\u001b[39mlit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m), F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      4\u001b[0m )\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "(df\n",
    " .select(F.col('YEAR').alias('year'), F.col('MONTH').alias('month'), F.col('DAY').alias('day'))\n",
    " .select('*', F.concat(F.col('year'), F.lit('-'), F.col('month'), F.lit('-'), F.col('day')).alias('date'))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LNcEXWT_TL1e"
   },
   "source": [
    "But we can also create DataFrames on the fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dt_bNtgPTL1g",
    "outputId": "70e46214-372f-4b0e-f422-80b04b2bfe3f"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType\n",
    "\n",
    "mySchema = StructType([\n",
    "    StructField('col_1', StringType(), True),\n",
    "    StructField('col_2', StringType(), True),\n",
    "    StructField('col_3', LongType(), False)\n",
    "])\n",
    "\n",
    "myRows = [Row('Hello', None, 1), \n",
    "          Row('World', '!', 2), \n",
    "          Row('HOW', None, 3)]\n",
    "\n",
    "\n",
    "myDf = spark.createDataFrame(myRows, mySchema)\n",
    "myDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>World</td>\n",
       "      <td>!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOW</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_1 col_2  col_3\n",
       "0  Hello  None      1\n",
       "1  World     !      2\n",
       "2    HOW  None      3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDf.toPandas().head() # collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mvT_damVTL1n"
   },
   "source": [
    "##### Select and selectExpr\n",
    "\n",
    "```select``` and ```selectExpr```allow you to do the DataFrame equivalent of SQL queries on a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-VaJn6qZTL1p",
    "outputId": "f3dbefc7-2b0e-4f3b-c033-16377fd1d91e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|DESTINATION_AIRPORT|\n",
      "+-------------------+\n",
      "|                SEA|\n",
      "|                PBI|\n",
      "+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('DESTINATION_AIRPORT').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('YEAR', 'int'),\n",
       " ('MONTH', 'int'),\n",
       " ('DAY', 'int'),\n",
       " ('DAY_OF_WEEK', 'int'),\n",
       " ('AIRLINE', 'string'),\n",
       " ('FLIGHT_NUMBER', 'int'),\n",
       " ('TAIL_NUMBER', 'string'),\n",
       " ('ORIGIN_AIRPORT', 'string'),\n",
       " ('DESTINATION_AIRPORT', 'string'),\n",
       " ('SCHEDULED_DEPARTURE', 'int'),\n",
       " ('DEPARTURE_TIME', 'int'),\n",
       " ('DEPARTURE_DELAY', 'int'),\n",
       " ('TAXI_OUT', 'int'),\n",
       " ('WHEELS_OFF', 'int'),\n",
       " ('SCHEDULED_TIME', 'int'),\n",
       " ('ELAPSED_TIME', 'int'),\n",
       " ('AIR_TIME', 'int'),\n",
       " ('DISTANCE', 'int'),\n",
       " ('WHEELS_ON', 'int'),\n",
       " ('TAXI_IN', 'int'),\n",
       " ('SCHEDULED_ARRIVAL', 'int'),\n",
       " ('ARRIVAL_TIME', 'int'),\n",
       " ('ARRIVAL_DELAY', 'int'),\n",
       " ('DIVERTED', 'int'),\n",
       " ('CANCELLED', 'int'),\n",
       " ('CANCELLATION_REASON', 'string'),\n",
       " ('AIR_SYSTEM_DELAY', 'int'),\n",
       " ('SECURITY_DELAY', 'int'),\n",
       " ('AIRLINE_DELAY', 'int'),\n",
       " ('LATE_AIRCRAFT_DELAY', 'int'),\n",
       " ('WEATHER_DELAY', 'int')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+-----------+-------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+----------------+--------------+-------------+-------------------+-------------+\n",
      "|year|month|day|day_of_week|flight_number|scheduled_departure|departure_time|departure_delay|taxi_out|wheels_off|scheduled_time|elapsed_time|air_time|distance|wheels_on|taxi_in|scheduled_arrival|arrival_time|arrival_delay|diverted|cancelled|air_system_delay|security_delay|airline_delay|late_aircraft_delay|weather_delay|\n",
      "+----+-----+---+-----------+-------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+----------------+--------------+-------------+-------------------+-------------+\n",
      "|2015|    1|  1|          4|           98|                  5|          2354|            -11|      21|        15|           205|         194|     169|    1448|      404|      4|              430|         408|          -22|       0|        0|            null|          null|         null|               null|         null|\n",
      "|2015|    1|  1|          4|         2336|                 10|             2|             -8|      12|        14|           280|         279|     263|    2330|      737|      4|              750|         741|           -9|       0|        0|            null|          null|         null|               null|         null|\n",
      "|2015|    1|  1|          4|          840|                 20|            18|             -2|      16|        34|           286|         293|     266|    2296|      800|     11|              806|         811|            5|       0|        0|            null|          null|         null|               null|         null|\n",
      "|2015|    1|  1|          4|          258|                 20|            15|             -5|      15|        30|           285|         281|     258|    2342|      748|      8|              805|         756|           -9|       0|        0|            null|          null|         null|               null|         null|\n",
      "|2015|    1|  1|          4|          135|                 25|            24|             -1|      11|        35|           235|         215|     199|    1448|      254|      5|              320|         259|          -21|       0|        0|            null|          null|         null|               null|         null|\n",
      "+----+-----+---+-----------+-------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+----------------+--------------+-------------+-------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df.select(cols).show(5)\n",
    "# Display all the columns with numeric type in lowercase. \n",
    "df.select([F.col(c).alias(c.lower()) for c, t in df.dtypes if t in ('int', 'double')]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ixueeTqtTL1v",
    "outputId": "b94bec4b-607a-4595-87ea-ab61d61a36be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+\n",
      "|DESTINATION_AIRPORT|AIR_TIME|\n",
      "+-------------------+--------+\n",
      "|                SEA|     169|\n",
      "|                PBI|     263|\n",
      "+-------------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('DESTINATION_AIRPORT', 'AIR_TIME').show(2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i7iZID7tTL11"
   },
   "source": [
    "You can refer columns in multiple ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gEX_bSSbTL13",
    "outputId": "4c268842-7d24-4850-a91f-cedd17088a2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+--------+\n",
      "|DESTINATION_AIRPORT|ORIGIN_AIRPORT|DISTANCE|\n",
      "+-------------------+--------------+--------+\n",
      "|                SEA|           ANC|    1448|\n",
      "|                PBI|           LAX|    2330|\n",
      "+-------------------+--------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr, col, column, lit\n",
    "# F.expr, F.col, F.col...\n",
    "df.select(\n",
    "    expr('DESTINATION_AIRPORT'),\n",
    "    col('ORIGIN_AIRPORT'),\n",
    "    column('DISTANCE')).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R0sIOHU2TL1-"
   },
   "source": [
    "And with a little bit more flexibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MTd5teRBTL2A",
    "outputId": "19893bef-b6a5-4662-a2b9-edbc25844ea6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [YEAR#17, MONTH#18, DAY#19, DAY_OF_WEEK#20, AIRLINE#21, FLIGHT_NUMBER#22, TAIL_NUMBER#23, ORIGIN_AIRPORT#24, DESTINATION_AIRPORT#25, SCHEDULED_DEPARTURE#26, DEPARTURE_TIME#27, DEPARTURE_DELAY#28, TAXI_OUT#29, WHEELS_OFF#30, SCHEDULED_TIME#31, ELAPSED_TIME#32, AIR_TIME#33, DISTANCE#34, WHEELS_ON#35, TAXI_IN#36, SCHEDULED_ARRIVAL#37, ARRIVAL_TIME#38, ARRIVAL_DELAY#39, DIVERTED#40, ... 9 more fields]\n",
      "+- InMemoryTableScan [AIRLINE#21, AIRLINE_DELAY#45, AIR_SYSTEM_DELAY#43, AIR_TIME#33, ARRIVAL_DELAY#39, ARRIVAL_TIME#38, CANCELLATION_REASON#42, CANCELLED#41, DAY#19, DAY_OF_WEEK#20, DEPARTURE_DELAY#28, DEPARTURE_TIME#27, DESTINATION_AIRPORT#25, DISTANCE#34, DIVERTED#40, ELAPSED_TIME#32, FLIGHT_NUMBER#22, LATE_AIRCRAFT_DELAY#46, MONTH#18, ORIGIN_AIRPORT#24, SCHEDULED_ARRIVAL#37, SCHEDULED_DEPARTURE#26, SCHEDULED_TIME#31, SECURITY_DELAY#44, ... 7 more fields]\n",
      "      +- InMemoryRelation [YEAR#17, MONTH#18, DAY#19, DAY_OF_WEEK#20, AIRLINE#21, FLIGHT_NUMBER#22, TAIL_NUMBER#23, ORIGIN_AIRPORT#24, DESTINATION_AIRPORT#25, SCHEDULED_DEPARTURE#26, DEPARTURE_TIME#27, DEPARTURE_DELAY#28, TAXI_OUT#29, WHEELS_OFF#30, SCHEDULED_TIME#31, ELAPSED_TIME#32, AIR_TIME#33, DISTANCE#34, WHEELS_ON#35, TAXI_IN#36, SCHEDULED_ARRIVAL#37, ARRIVAL_TIME#38, ARRIVAL_DELAY#39, DIVERTED#40, ... 7 more fields], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "            +- FileScan csv [YEAR#17,MONTH#18,DAY#19,DAY_OF_WEEK#20,AIRLINE#21,FLIGHT_NUMBER#22,TAIL_NUMBER#23,ORIGIN_AIRPORT#24,DESTINATION_AIRPORT#25,SCHEDULED_DEPARTURE#26,DEPARTURE_TIME#27,DEPARTURE_DELAY#28,TAXI_OUT#29,WHEELS_OFF#30,SCHEDULED_TIME#31,ELAPSED_TIME#32,AIR_TIME#33,DISTANCE#34,WHEELS_ON#35,TAXI_IN#36,SCHEDULED_ARRIVAL#37,ARRIVAL_TIME#38,ARRIVAL_DELAY#39,DIVERTED#40,... 7 more fields] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/Users/luisroman/Documents/Projects/Teaching/ITAM/FuentesDeDatos/..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<YEAR:int,MONTH:int,DAY:int,DAY_OF_WEEK:int,AIRLINE:string,FLIGHT_NUMBER:int,TAIL_NUMBER:st...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df.select(expr(...))\n",
    "# .alias\n",
    "# as \n",
    "# withColumnRenamed\n",
    "df.selectExpr(\n",
    "    '*', # Include all original columns\n",
    "    'DESTINATION_AIRPORT as destiny',\n",
    "    'DISTANCE*2 as round_trip').explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NHbXNRArTL2E",
    "outputId": "241d9490-1f04-4c87-edef-b7c526241481"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/22 18:24:17 WARN CacheManager: Asked to cache already cached data.\n",
      "== Physical Plan ==\n",
      "*(1) Project [DESTINATION_AIRPORT#25 AS destiny#3180, ORIGIN_AIRPORT#24, DISTANCE#34, (DISTANCE#34 < 1000) AS near_by#3181]\n",
      "+- InMemoryTableScan [DESTINATION_AIRPORT#25, DISTANCE#34, ORIGIN_AIRPORT#24]\n",
      "      +- InMemoryRelation [YEAR#17, MONTH#18, DAY#19, DAY_OF_WEEK#20, AIRLINE#21, FLIGHT_NUMBER#22, TAIL_NUMBER#23, ORIGIN_AIRPORT#24, DESTINATION_AIRPORT#25, SCHEDULED_DEPARTURE#26, DEPARTURE_TIME#27, DEPARTURE_DELAY#28, TAXI_OUT#29, WHEELS_OFF#30, SCHEDULED_TIME#31, ELAPSED_TIME#32, AIR_TIME#33, DISTANCE#34, WHEELS_ON#35, TAXI_IN#36, SCHEDULED_ARRIVAL#37, ARRIVAL_TIME#38, ARRIVAL_DELAY#39, DIVERTED#40, ... 7 more fields], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "            +- FileScan csv [YEAR#17,MONTH#18,DAY#19,DAY_OF_WEEK#20,AIRLINE#21,FLIGHT_NUMBER#22,TAIL_NUMBER#23,ORIGIN_AIRPORT#24,DESTINATION_AIRPORT#25,SCHEDULED_DEPARTURE#26,DEPARTURE_TIME#27,DEPARTURE_DELAY#28,TAXI_OUT#29,WHEELS_OFF#30,SCHEDULED_TIME#31,ELAPSED_TIME#32,AIR_TIME#33,DISTANCE#34,WHEELS_ON#35,TAXI_IN#36,SCHEDULED_ARRIVAL#37,ARRIVAL_TIME#38,ARRIVAL_DELAY#39,DIVERTED#40,... 7 more fields] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/Users/luisroman/Documents/Projects/Teaching/ITAM/FuentesDeDatos/..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<YEAR:int,MONTH:int,DAY:int,DAY_OF_WEEK:int,AIRLINE:string,FLIGHT_NUMBER:int,TAIL_NUMBER:st...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = df.cache()\n",
    "df1.selectExpr(\n",
    "    'DESTINATION_AIRPORT as destiny',\n",
    "    'ORIGIN_AIRPORT',\n",
    "    'DISTANCE',\n",
    "    'DISTANCE < 1000 as near_by').explain()\n",
    "#.filter(col('near_by')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-hKiTGdQTL2O"
   },
   "source": [
    "With ```selectExpr```we can also compute aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3376xnBATL2P",
    "outputId": "759cd607-f4f8-4f0a-82b5-d0d564c7d115"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------+---------+--------------+\n",
      "|    mean_distance|dist_org|dist_dest|round_distance|\n",
      "+-----------------+--------+---------+--------------+\n",
      "|822.3564947305235|     628|      629|        822.36|\n",
      "+-----------------+--------+---------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 32:=================>                                      (5 + 11) / 16]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(df1.selectExpr('avg(DISTANCE) as mean_distance', \n",
    "               'count(distinct(ORIGIN_AIRPORT)) as dist_org', \n",
    "               'count(distinct(DESTINATION_AIRPORT)) as dist_dest')\n",
    " .select('*', F.round('mean_distance', 2).alias('round_distance'))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S0mNeVjsTL2V"
   },
   "source": [
    "##### Adding Columns\n",
    "\n",
    "We can add columns to a Spark DataFrame within the select statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4UgYuH53TL2X",
    "outputId": "47dc674b-c277-4c6b-b68a-68b25915aab1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+---------------+\n",
      "|ORIGIN_AIRPORT|col_2|pasted_together|\n",
      "+--------------+-----+---------------+\n",
      "|           ANC|   33|         ANC-33|\n",
      "|           LAX|   33|         LAX-33|\n",
      "|           SFO|   33|         SFO-33|\n",
      "|           LAX|   33|         LAX-33|\n",
      "+--------------+-----+---------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select(col('ORIGIN_AIRPORT'), \n",
    "           lit(33).alias('col_2') \n",
    "           ).withColumn('pasted_together', \n",
    "                        F.concat('ORIGIN_AIRPORT', F.lit('-'), 'col_2')).show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lNs76dXkTL2d"
   },
   "source": [
    "Or using the more formal function ```withColumn```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4zpyMT9gTL2e",
    "outputId": "b5c291ac-022f-4859-84d4-03d70a0dd7f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---+\n",
      "|ORIGIN_AIRPORT|One|\n",
      "+--------------+---+\n",
      "|           ANC|  1|\n",
      "|           LAX|  1|\n",
      "+--------------+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col('ORIGIN_AIRPORT')).withColumn('One', lit(1)).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5O6fJn9STL2w"
   },
   "source": [
    "The full functionality of ```withColumn```can be enhanced by using ```udfs```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6VLnIL3dTL2y"
   },
   "source": [
    "##### Renaming columns\n",
    "\n",
    "We can rename columns either with an alias, a ```withColumn``` or ```withColumnRenamed```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a3EUNhizTL2z",
    "outputId": "ec9eccf2-cf90-49e7-9a3e-de318c8e294b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|destiny|\n",
      "+-------+\n",
      "|    SEA|\n",
      "|    PBI|\n",
      "+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col('DESTINATION_AIRPORT').alias('destiny')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A7ig-Q09TL25",
    "outputId": "5c7c5d02-8ef7-4112-a244-2c49eb20fb76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+\n",
      "|DESTINATION_AIRPORT|destiny|\n",
      "+-------------------+-------+\n",
      "|                SEA|    SEA|\n",
      "|                PBI|    PBI|\n",
      "+-------------------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('DESTINATION_AIRPORT').withColumn('destiny', col('DESTINATION_AIRPORT')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ad3w1zU7TL2-",
    "outputId": "d01e79d1-3c7a-4605-e493-d96d795b0ab9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|destiny|\n",
      "+-------+\n",
      "|    SEA|\n",
      "|    PBI|\n",
      "+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('DESTINATION_AIRPORT').withColumnRenamed('DESTINATION_AIRPORT', 'destiny').show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aQPkHL5qTL3C"
   },
   "source": [
    "##### Removing columns\n",
    "\n",
    "We can remove one or multiple columns with ```drop````\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "14_vAhIeTL3O",
    "outputId": "4be51ce8-80ff-459f-d405-84d64caf5241"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|DISTANCE|near_by|\n",
      "+--------+-------+\n",
      "|    1448|  false|\n",
      "|    2330|  false|\n",
      "+--------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col('DESTINATION_AIRPORT').alias('dest'), \n",
    "          col('ORIGIN_AIRPORT').alias('origin'), \n",
    "          col('DISTANCE'), \n",
    "          expr('DISTANCE < 1000').alias('near_by')).drop(*['dest', 'origin']).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nj-oK3FmTL3S"
   },
   "source": [
    "##### Changing a Column's type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RBlE_ml0TL3U",
    "outputId": "7e61f186-d008-43fa-d7c9-d0c3ebfadf9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|DISTANCE|\n",
      "+--------+\n",
      "|  1448.0|\n",
      "|  2330.0|\n",
      "+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col('DISTANCE').cast('float')).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z7NaF8ViTL3X"
   },
   "source": [
    "##### Filtering rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SGW9vds-TL3Y",
    "outputId": "2b107c55-659a-432f-90ef-df7f96a9e092"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+--------+-------+\n",
      "|DESTINATION_AIRPORT|ORIGIN_AIRPORT|DISTANCE|near_by|\n",
      "+-------------------+--------------+--------+-------+\n",
      "|                DFW|           PHX|     868|   true|\n",
      "|                DFW|           PHX|     868|   true|\n",
      "|                SEA|           GEG|     224|   true|\n",
      "|                ITO|           HNL|     216|   true|\n",
      "|                SFO|           ONT|     363|   true|\n",
      "+-------------------+--------------+--------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col('DESTINATION_AIRPORT'), \n",
    "          col('ORIGIN_AIRPORT'), \n",
    "          col('DISTANCE'), \n",
    "          expr('DISTANCE < 1000').alias('near_by'))\\\n",
    ".where(col('near_by')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KlUZIWNmTL3d",
    "outputId": "11a99698-ccb4-4f26-abaa-bd8bbf3cfe88"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:===>                                                     (1 + 15) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+---------+\n",
      "|DESTINATION_AIRPORT|ORIGIN_AIRPORT|all_trips|\n",
      "+-------------------+--------------+---------+\n",
      "|                ATL|           GSP|     2471|\n",
      "|                ORD|           PDX|     2164|\n",
      "+-------------------+--------------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "(df\n",
    " .groupBy(col('DESTINATION_AIRPORT'), \n",
    "          col('ORIGIN_AIRPORT'))\n",
    " .agg(F.count('*').alias('all_trips'))\n",
    " .where(col('all_trips') > 100)).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eYANG2MLTL3i",
    "outputId": "e3c5bf33-f703-4eb6-c833-04ee9893ca9c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:===>                                                    (1 + 15) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+-----+\n",
      "|DESTINATION_AIRPORT|ORIGIN_AIRPORT|count|\n",
      "+-------------------+--------------+-----+\n",
      "|                ATL|           GSP| 2471|\n",
      "|                ORD|           PDX| 2164|\n",
      "+-------------------+--------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 10:============================>                            (8 + 8) / 16]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.groupBy(col('DESTINATION_AIRPORT'), \n",
    "           col('ORIGIN_AIRPORT')).count()\\\n",
    ".where(col('count') > 100).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OxKK-qv9TL3m",
    "outputId": "d968c78e-cc71-444c-80cd-ec6d06fdc803"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:===>                                                    (1 + 15) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+-----+\n",
      "|DESTINATION_AIRPORT|ORIGIN_AIRPORT|count|\n",
      "+-------------------+--------------+-----+\n",
      "|                PBI|           DCA|  978|\n",
      "|                MDW|           MEM|  626|\n",
      "+-------------------+--------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 13:==============>                                         (4 + 12) / 16]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(df.groupBy(col('DESTINATION_AIRPORT'), \n",
    "           col('ORIGIN_AIRPORT'))\n",
    " .count()\n",
    ".where((col('count') > 100)) \n",
    ".where(col('count') < 1000)).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i0hZ3oiZTL3q"
   },
   "source": [
    "##### Getting unique rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jphMgmA0TL3u",
    "outputId": "ac0f0706-bf86-4584-bb82-8ac9f19f6c36"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:===>                                                    (1 + 15) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+\n",
      "|ORIGIN_AIRPORT|DESTINATION_AIRPORT|\n",
      "+--------------+-------------------+\n",
      "|           BQN|                MCO|\n",
      "|           PHL|                MCO|\n",
      "|           MCI|                IAH|\n",
      "|           SPI|                ORD|\n",
      "|           SNA|                PHX|\n",
      "+--------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 16:==============>                                         (4 + 12) / 16]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select('ORIGIN_AIRPORT', 'DESTINATION_AIRPORT').distinct().show(5) # coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+\n",
      "|(NOT CAST((FLIGHT_NUMBER % 2) AS BOOLEAN))|\n",
      "+------------------------------------------+\n",
      "|                                      true|\n",
      "|                                      true|\n",
      "|                                      true|\n",
      "|                                      true|\n",
      "|                                     false|\n",
      "+------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(~(F.col('FLIGHT_NUMBER') % 2).cast('boolean')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+\n",
      "|FLIGHT_NUMBER|          div_col|\n",
      "+-------------+-----------------+\n",
      "|           98|            div 2|\n",
      "|         2336|            div 2|\n",
      "|          840|            div 2|\n",
      "|          258|            div 2|\n",
      "|          135|            div 3|\n",
      "|          806|            div 2|\n",
      "|          612|            div 2|\n",
      "|         2013|            div 3|\n",
      "|         1112|            div 2|\n",
      "|         1173|            div 3|\n",
      "|         2336|            div 2|\n",
      "|         1674|            div 2|\n",
      "|         1434|            div 2|\n",
      "|         2324|            div 2|\n",
      "|         2440|            div 2|\n",
      "|          108|            div 2|\n",
      "|         1560|            div 2|\n",
      "|         1197|            div 3|\n",
      "|          122|            div 2|\n",
      "|         1670|            div 2|\n",
      "|          520|            div 2|\n",
      "|          371|not div by 2 or 3|\n",
      "|          214|            div 2|\n",
      "|          115|not div by 2 or 3|\n",
      "|         1450|            div 2|\n",
      "|         1545|            div 3|\n",
      "|          130|            div 2|\n",
      "|          597|            div 3|\n",
      "|          413|not div by 2 or 3|\n",
      "|         2392|            div 2|\n",
      "+-------------+-----------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(F.col('FLIGHT_NUMBER'), \n",
    "          (F.when(~(F.col('FLIGHT_NUMBER') % 2).cast('boolean'), 'div 2')\n",
    "           .when(~(F.col('FLIGHT_NUMBER') % 3).cast('boolean'), 'div 3')\n",
    "           .otherwise('not div by 2 or 3')\n",
    "          ).alias('div_col')).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "93IDMWb8TL3y"
   },
   "source": [
    "##### Aggregations and Grouping with maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "az20xfHfTL30",
    "outputId": "418d5bd2-fa28-488b-f488-db086d8e5b89"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, countDistinct, approx_count_distinct, first, last, min, max, sum, sumDistinct, avg, collect_set, collect_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nMw3DF1fTL35"
   },
   "source": [
    "The first function worth going over is **count**, with the sole exception that in this example it will perform as a transformation instead of an action. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qFd4_KD4TL37",
    "outputId": "f9f0bc30-8aaa-4bc6-b493-722658c5be54"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 27:>                                                       (0 + 16) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|all_carriers|\n",
      "+------------+\n",
      "|     5819079|\n",
      "+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 27:===>                                                    (1 + 15) / 16]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, countDistinct, approx_count_distinct, first, last, min, max, sum, sumDistinct, avg, collect_set, collect_list\n",
    "\n",
    "df.select(count('AIRLINE').alias('all_carriers')).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xJrszHgiTL4A"
   },
   "source": [
    "Sometimes we are not interested in the total count but in the number of different instances of the variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k00Tz3nbTL4B",
    "outputId": "2940b51d-430f-4092-cb0f-85cefdf5c9e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|unique_carriers|\n",
      "+---------------+\n",
      "|             14|\n",
      "+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(countDistinct('AIRLINE').alias('unique_carriers')).show()\n",
    "df.groupBy('AIRLINE').count().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5rWKGAB1TL4E"
   },
   "source": [
    "If the dataset is very large, the exact count of different instances might be irrelevant, but an approximation with certain degreee of accuracy might be good enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function approx_count_distinct in module pyspark.sql.functions:\n",
      "\n",
      "approx_count_distinct(col: 'ColumnOrName', rsd: Optional[float] = None) -> pyspark.sql.column.Column\n",
      "    Aggregate function: returns a new :class:`~pyspark.sql.Column` for approximate distinct count\n",
      "    of column `col`.\n",
      "    \n",
      "    .. versionadded:: 2.1.0\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    col : :class:`~pyspark.sql.Column` or str\n",
      "    rsd : float, optional\n",
      "        maximum relative standard deviation allowed (default = 0.05).\n",
      "        For rsd < 0.01, it is more efficient to use :func:`count_distinct`\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df.agg(approx_count_distinct(df.age).alias('distinct_ages')).collect()\n",
      "    [Row(distinct_ages=2)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(approx_count_distinct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DQapwTvRTL4G",
    "outputId": "7d62b824-7d51-4bf7-b2f7-f28c77c0c701"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 45:>                                                       (0 + 16) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|unique_approx|\n",
      "+-------------+\n",
      "|         4715|\n",
      "+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 45:===>                                                    (1 + 15) / 16]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(df\n",
    " .select(approx_count_distinct('TAIL_NUMBER')\n",
    "         .alias('unique_approx')).show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eCJuMVpYTL4L"
   },
   "source": [
    "You can get the first and last values from a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KRnb2jmITL4M",
    "outputId": "5b251390-ece7-4f26-811f-8cc7c7f3055e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 48:>                                                       (0 + 16) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+\n",
      "|first_tailnum|last_tailnum|\n",
      "+-------------+------------+\n",
      "|       N407AS|      N534JB|\n",
      "+-------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 48:=============================================>          (13 + 3) / 16]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "    first('TAIL_NUMBER').alias('first_tailnum'),\n",
    "    last('TAIL_NUMBER').alias('last_tailnum')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lL2s5oCdTL4S"
   },
   "source": [
    "You can also compute the min, max, sum, avg values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ZNLf8n1TL4T",
    "outputId": "f94baba7-8778-4a28-9040-8b6612128101"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+-----------------+------------+\n",
      "|min_distance|sum_distance|     avg_distance|max_distance|\n",
      "+------------+------------+-----------------+------------+\n",
      "|          21|  4785357409|822.3564947305235|        4983|\n",
      "+------------+------------+-----------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 54:>                                                       (0 + 16) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+-----------------+------------+\n",
      "|min_distance|sum_distance|     avg_distance|max_distance|\n",
      "+------------+------------+-----------------+------------+\n",
      "|          21|  4785357409|822.3564947305235|        4983|\n",
      "+------------+------------+-----------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 54:===>                                                    (1 + 15) / 16]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "    min(col('DISTANCE')).alias('min_distance'),\n",
    "    sum(col('DISTANCE')).alias('sum_distance'),\n",
    "    avg(col('DISTANCE')).alias('avg_distance'),\n",
    "    max(col('DISTANCE')).alias('max_distance'),\n",
    ").show()\n",
    "\n",
    "df.selectExpr('min(DISTANCE) as min_distance', \n",
    "              'sum(DISTANCE) as sum_distance', \n",
    "              'avg(DISTANCE) as avg_distance',\n",
    "              'max(DISTANCE) as max_distance').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "27-kdeTYTL4Y"
   },
   "source": [
    "And some more complex aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pYoQ_vgETL4b",
    "outputId": "178adc9a-5a8f-49f9-f2fc-e2516ca480ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_planes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[N557AS, N579JB, N3AGAA, N533US, N612JB, N827U...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       unique_planes\n",
       "0  [N557AS, N579JB, N3AGAA, N533US, N612JB, N827U..."
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = df.select(\n",
    "    collect_set('TAIL_NUMBER').alias('unique_planes')\n",
    "    ).toPandas()\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4nBI9nCITL4g"
   },
   "source": [
    "### Window Functions\n",
    "\n",
    "Window functions allow you to apply aggregated computations through different data partitions and to interoperate them with individual registries. These are particularly useful since they allow you to get rid of loops (for, while,...).\n",
    "\n",
    "Let's take a look at some examples:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RBqUPpOTTL4h",
    "outputId": "f8e5d5b7-fcd4-432e-a63c-5363254b5cc8"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, avg, abs, monotonically_increasing_id, ntile, sum, lit, dense_rank, collect_list\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "22FjP5joTL4k"
   },
   "source": [
    "So, there are multiple columns among which we could perform some interesting computations. For example, it might be of interest to know which planes tend to have larger delays than the average plane per carrier. In order to answer this question, we must perform the following steps:\n",
    "\n",
    "* Define the fields among which we are going to partition the data in order to compute the aggregates. In this case, we are interested in the variable _carrier_\n",
    "\n",
    "* Define the function to apply and how it is going to interplay with the individual entries. \n",
    "\n",
    "* Apply the function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-------+-------+-------+--------+---------+---------+--------+----+---------+---------+--------+---------+\n",
      "|MONTH|DAY|WEEKDAY|AIRLINE|ORG_AIR|DEST_AIR|SCHED_DEP|DEP_DELAY|AIR_TIME|DIST|SCHED_ARR|ARR_DELAY|DIVERTED|CANCELLED|\n",
      "+-----+---+-------+-------+-------+--------+---------+---------+--------+----+---------+---------+--------+---------+\n",
      "|    1|  1|      4|     WN|    LAX|     SLC|     1625|     58.0|    94.0| 590|     1905|     65.0|       0|        0|\n",
      "|    1|  1|      4|     UA|    DEN|     IAD|      823|      7.0|   154.0|1452|     1333|    -13.0|       0|        0|\n",
      "|    1|  1|      4|     MQ|    DFW|     VPS|     1305|     36.0|    85.0| 641|     1453|     35.0|       0|        0|\n",
      "|    1|  1|      4|     AA|    DFW|     DCA|     1555|      7.0|   126.0|1192|     1935|     -7.0|       0|        0|\n",
      "|    1|  1|      4|     WN|    LAX|     MCI|     1720|     48.0|   166.0|1363|     2225|     39.0|       0|        0|\n",
      "+-----+---+-------+-------+-------+--------+---------+---------+--------+----+---------+---------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights = spark.read.csv('../class_17/data/flights.csv', header=True)\n",
    "flights.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_rank = Window().partitionBy(F.col('airline')).orderBy(F.col('n_trips').desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------+-------+-----+\n",
      "|airline|origin|destiny|n_trips|top_n|\n",
      "+-------+------+-------+-------+-----+\n",
      "|     AA|   DFW|    LAX|    175|    1|\n",
      "|     AA|   LAX|    DFW|    175|    1|\n",
      "|     AA|   DFW|    ORD|    163|    2|\n",
      "|     AA|   ORD|    DFW|    160|    3|\n",
      "|     AA|   ORD|    LGA|    152|    4|\n",
      "|     AA|   DFW|    AUS|    146|    5|\n",
      "|     AS|   LAX|    SEA|    157|    1|\n",
      "|     AS|   LAS|    SEA|     80|    2|\n",
      "|     AS|   LAX|    PDX|     76|    3|\n",
      "|     AS|   SFO|    SEA|     74|    4|\n",
      "|     AS|   DEN|    SEA|     50|    5|\n",
      "|     B6|   LAX|    JFK|     71|    1|\n",
      "|     B6|   SFO|    JFK|     50|    2|\n",
      "|     B6|   SFO|    LGB|     36|    3|\n",
      "|     B6|   LAS|    LGB|     35|    4|\n",
      "|     B6|   ORD|    JFK|     34|    5|\n",
      "|     DL|   ATL|    MCO|    187|    1|\n",
      "|     DL|   ATL|    LGA|    154|    2|\n",
      "|     DL|   ATL|    TPA|    147|    3|\n",
      "|     DL|   ATL|    FLL|    141|    4|\n",
      "+-------+------+-------+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the combination of origin destination with more flights per airline.\n",
    "t_data = (flights\n",
    "          .groupBy(\n",
    "              F.col('AIRLINE').alias('airline'), \n",
    "              F.col('ORG_AIR').alias('origin'), \n",
    "              F.col('DEST_AIR').alias('destiny'))\n",
    "          .agg(F.count('*').alias('n_trips'))\n",
    "          .orderBy(F.col('airline'), F.col('n_trips').desc())\n",
    "          .select('*', F.dense_rank().over(w_rank).alias('top_n'))\n",
    "          .filter(F.col('top_n') <= 5)\n",
    ")\n",
    "\n",
    "t_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6_KuvqRITL4l"
   },
   "source": [
    "##### Select variables of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "plQn6E6RTL4m",
    "outputId": "a5382ac8-40d2-4fc8-b8ad-dc4c133f150d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----------+-------+-------------+\n",
      "|MONTH|YEAR|TAIL_NUMBER|AIRLINE|ARRIVAL_DELAY|\n",
      "+-----+----+-----------+-------+-------------+\n",
      "|    1|2015|     N407AS|     AS|          -22|\n",
      "|    1|2015|     N3KUAA|     AA|           -9|\n",
      "|    1|2015|     N171US|     US|            5|\n",
      "|    1|2015|     N3HYAA|     AA|           -9|\n",
      "|    1|2015|     N527AS|     AS|          -21|\n",
      "+-----+----+-----------+-------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ex1_data = df.select(col('MONTH'),\n",
    "                     col('YEAR'),\n",
    "                     col('TAIL_NUMBER'), \n",
    "                     col('AIRLINE'), \n",
    "                     col('ARRIVAL_DELAY'))\\\n",
    ".filter(col('TAIL_NUMBER').isNotNull())\\\n",
    ".filter(col('ARRIVAL_DELAY').isNotNull())\n",
    "\n",
    "ex1_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A2aZoOBuTL4q"
   },
   "source": [
    "##### Determine variables for partitioning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "upBDbWU2TL4s"
   },
   "outputs": [],
   "source": [
    "windowSpec = Window.partitionBy(ex1_data['AIRLINE']).orderBy(ex1_data['AIRLINE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LXmF0qUrTL4z"
   },
   "source": [
    "##### Define function to apply\n",
    "\n",
    "\n",
    "In this case we are interested in finding out how the delay of each plane compares with the average delay of the given airline, thus, we are going to compute the difference between the average and the particular delays. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FVqUyHd5TL42"
   },
   "outputs": [],
   "source": [
    "average_delay = avg(ex1_data['ARRIVAL_DELAY']).over(windowSpec) \n",
    "average_delay_diff = avg(ex1_data['ARRIVAL_DELAY']).over(windowSpec) - ex1_data['ARRIVAL_DELAY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kYTknxkRTL47"
   },
   "source": [
    "##### Apply function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LK0zMDg4TL48",
    "outputId": "67af4166-9817-4632-80c2-8d21522e092a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 67:=============================================>            (7 + 2) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----------+-------+-------------+------------------+-------------------+\n",
      "|MONTH|YEAR|TAIL_NUMBER|AIRLINE|ARRIVAL_DELAY|     AVERAGE_DELAY|    DELAY_DEVIATION|\n",
      "+-----+----+-----------+-------+-------------+------------------+-------------------+\n",
      "|    1|2015|     N598AA|     AA|         1971|3.4513721447256764|-1967.5486278552744|\n",
      "|    8|2015|     N479AA|     AA|         1898|3.4513721447256764|-1894.5486278552744|\n",
      "|    9|2015|     N3CAAA|     AA|         1665|3.4513721447256764|-1661.5486278552744|\n",
      "|   11|2015|     N489AA|     AA|         1638|3.4513721447256764|-1634.5486278552744|\n",
      "|    7|2015|     N3LEAA|     AA|         1636|3.4513721447256764|-1632.5486278552744|\n",
      "|   12|2015|     N4XKAA|     AA|         1636|3.4513721447256764|-1632.5486278552744|\n",
      "|    2|2015|     N028AA|     AA|         1627|3.4513721447256764|-1623.5486278552744|\n",
      "|    3|2015|     N559AA|     AA|         1598|3.4513721447256764|-1594.5486278552744|\n",
      "|    1|2015|     N5DGAA|     AA|         1593|3.4513721447256764|-1589.5486278552744|\n",
      "|    3|2015|     N5DJAA|     AA|         1576|3.4513721447256764|-1572.5486278552744|\n",
      "+-----+----+-----------+-------+-------------+------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 67:===================================================>      (8 + 1) / 9]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ex1_data = ex1_data.select(col('MONTH'),\n",
    "                         col('YEAR'),\n",
    "                         col('TAIL_NUMBER'), \n",
    "                         col('AIRLINE'), \n",
    "                         col('ARRIVAL_DELAY'), \n",
    "                        average_delay.alias('AVERAGE_DELAY'),\n",
    "                        average_delay_diff.alias('DELAY_DEVIATION'))\n",
    "ex1_data.sort(col('AIRLINE'), \n",
    "              col('DELAY_DEVIATION')).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gwM-r-gYTL5D"
   },
   "source": [
    "Now we have an idea of which planes have the largest delays! Let us suppose that we are interested in comparing the top 5 planes with the largest delays between airlines. We can do this with another window function.\n",
    "\n",
    "##### Determine variables for partitioning the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qlWARYH6TL5E"
   },
   "outputs": [],
   "source": [
    "windowSpec = Window.partitionBy(ex1_data['AIRLINE']).orderBy(ex1_data['AIRLINE'], \n",
    "                                                             ex1_data['DELAY_DEVIATION'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MRIipVMaTL5I"
   },
   "source": [
    "##### Define function to apply\n",
    "\n",
    "In this case, we are interested in computing a ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cPvVgnSSTL5J"
   },
   "outputs": [],
   "source": [
    "rank_func = dense_rank().over(windowSpec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rw5iu1UDTL5M"
   },
   "source": [
    "##### Apply function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OVuVdohCTL5Q",
    "outputId": "73eae6e7-bb09-4be5-bc12-e077a06aae10"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 70:===================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----------+-------+-------------+-------------------+----------+\n",
      "|MONTH|YEAR|TAIL_NUMBER|AIRLINE|ARRIVAL_DELAY|    DELAY_DEVIATION|DELAY_RANK|\n",
      "+-----+----+-----------+-------+-------------+-------------------+----------+\n",
      "|    1|2015|     N598AA|     AA|         1971|-1967.5486278552744|         1|\n",
      "|    8|2015|     N479AA|     AA|         1898|-1894.5486278552744|         2|\n",
      "|    9|2015|     N3CAAA|     AA|         1665|-1661.5486278552744|         3|\n",
      "|   11|2015|     N489AA|     AA|         1638|-1634.5486278552744|         4|\n",
      "|   12|2015|     N4XKAA|     AA|         1636|-1632.5486278552744|         5|\n",
      "|    7|2015|     N3LEAA|     AA|         1636|-1632.5486278552744|         5|\n",
      "|    6|2015|     N307AS|     AS|          950| -950.9765630924119|         1|\n",
      "|    3|2015|     N760AS|     AS|          853| -853.9765630924119|         2|\n",
      "|    4|2015|     N408AS|     AS|          820| -820.9765630924119|         3|\n",
      "|    7|2015|     N708AS|     AS|          813| -813.9765630924119|         4|\n",
      "|   12|2015|     N433AS|     AS|          791| -791.9765630924119|         5|\n",
      "|   12|2015|     N828JB|     B6|         1002| -995.3221391990597|         1|\n",
      "|    2|2015|     N247JB|     B6|          952| -945.3221391990597|         2|\n",
      "|   12|2015|     N503JB|     B6|          895| -888.3221391990597|         3|\n",
      "|   12|2015|     N639JB|     B6|          760| -753.3221391990597|         4|\n",
      "|    3|2015|     N766JB|     B6|          749| -742.3221391990597|         5|\n",
      "|    5|2015|     N315NB|     DL|         1274|-1273.8132463876361|         1|\n",
      "|   12|2015|     N315US|     DL|         1211|-1210.8132463876361|         2|\n",
      "|    8|2015|     N900PC|     DL|         1189|-1188.8132463876361|         3|\n",
      "|    6|2015|     N925AT|     DL|         1184|-1183.8132463876361|         4|\n",
      "|    5|2015|     N916DE|     DL|         1181|-1180.8132463876361|         5|\n",
      "|   12|2015|     N920EV|     EV|         1223|-1216.4146213082602|         1|\n",
      "|    6|2015|     N847AS|     EV|         1196|-1189.4146213082602|         2|\n",
      "|    6|2015|     N615QX|     EV|         1142|-1135.4146213082602|         3|\n",
      "|   12|2015|     N741EV|     EV|         1054|-1047.4146213082602|         4|\n",
      "|   12|2015|     N741EV|     EV|         1044|-1037.4146213082602|         5|\n",
      "|    3|2015|     N935FR|     F9|         1101|-1088.4952935952936|         1|\n",
      "|    3|2015|     N953FR|     F9|         1005| -992.4952935952936|         2|\n",
      "|   11|2015|     N927FR|     F9|          913| -900.4952935952936|         3|\n",
      "|    2|2015|     N219FR|     F9|          839| -826.4952935952936|         4|\n",
      "+-----+----+-----------+-------+-------------+-------------------+----------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top_delay = 5 # We are interested in the top 5\n",
    "\n",
    "ex2_data = ex1_data.filter(col('DELAY_DEVIATION') < 0)\\\n",
    ".select(col('MONTH'),\n",
    "        col('YEAR'),\n",
    "        col('TAIL_NUMBER'), \n",
    "        col('AIRLINE'), \n",
    "        col('ARRIVAL_DELAY'), \n",
    "        col('DELAY_DEVIATION'), \n",
    "        rank_func.alias('DELAY_RANK'))\\\n",
    ".filter(col('DELAY_RANK') <= top_delay)\\\n",
    ".sort(col('AIRLINE'),  col('DELAY_RANK'))\n",
    "\n",
    "ex2_data.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+--------+------------------+\n",
      "|TAIL_NUMBER|AIRLINE|DISTANCE|      percent_dist|\n",
      "+-----------+-------+--------+------------------+\n",
      "|     N515NK|     NK|     965|0.5070456133176575|\n",
      "|     N532NK|     NK|     965|0.5070456133176575|\n",
      "|     N532NK|     NK|     965|0.5070456133176575|\n",
      "|     N529NK|     NK|     965|0.5070456133176575|\n",
      "|     N529NK|     NK|     965|0.5070456133176575|\n",
      "|     N529NK|     NK|     965|0.5070456133176575|\n",
      "|     N529NK|     NK|     965|0.5070456133176575|\n",
      "|     N505NK|     NK|     965|0.5070456133176575|\n",
      "|     N505NK|     NK|     965|0.5070456133176575|\n",
      "|     N505NK|     NK|     965|0.5070456133176575|\n",
      "|     N505NK|     NK|     965|0.5070456133176575|\n",
      "|     N515NK|     NK|     965|0.5070456133176575|\n",
      "|     N515NK|     NK|     965|0.5070456133176575|\n",
      "|     N526NK|     NK|     965|0.5070456133176575|\n",
      "|     N526NK|     NK|     965|0.5070456133176575|\n",
      "|     N510NK|     NK|     965|0.5070456133176575|\n",
      "|     N510NK|     NK|     965|0.5070456133176575|\n",
      "|     N507NK|     NK|     965|0.5070456133176575|\n",
      "|     N507NK|     NK|     965|0.5070456133176575|\n",
      "|     N507NK|     NK|     965|0.5070456133176575|\n",
      "+-----------+-------+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df.groupby('AIRLINE').select(F.expr('percentile_approx(DISTANCE, array(.25, .5, .75))')).show()\n",
    "# [373, 647, 1065]\n",
    "ws = Window.partitionBy(F.col('AIRLINE')).orderBy(F.col('DISTANCE').asc())\n",
    "\n",
    "(df\n",
    " .select(F.col('TAIL_NUMBER'),\n",
    "         F.col('AIRLINE'),\n",
    "         F.col('DISTANCE'),\n",
    "         F.percent_rank().over(ws).alias('percent_dist'))\n",
    " .filter(F.col('percent_dist') > .5)\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pd4n8Y_-TL5W"
   },
   "outputs": [],
   "source": [
    "### Otras funciones\n",
    "from pyspark.sql.functions import col, count, countDistinct, \\\n",
    "approx_count_distinct, first, last, min, max, sum, sumDistinct, avg,\\\n",
    "collect_set, collect_list, percent_rank, lag, lead, when, size, element_at\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eQFWI_NPTL5c"
   },
   "outputs": [],
   "source": [
    "empsalary = spark.createDataFrame([\n",
    "  (\"sales\",     1,  \"Alice\",  5000, [\"game\",  \"ski\"]),\n",
    "  (\"personnel\", 2,  \"Olivia\", 3900, [\"game\",  \"ski\"]),\n",
    "  (\"sales\",     3,  \"Ella\",   4800, [\"skate\", \"ski\"]),\n",
    "  (\"sales\",     4,  \"Ebba\",   4800, [\"game\",  \"ski\"]),\n",
    "  (\"personnel\", 5,  \"Lilly\",  3500, [\"climb\", \"ski\"]),\n",
    "  (\"develop\",   7,  \"Astrid\", 4200, [\"game\",  \"ski\"]),\n",
    "  (\"develop\",   8,  \"Saga\",   6000, [\"kajak\", \"ski\"]),\n",
    "  (\"develop\",   9,  \"Freja\",  4500, [\"game\",  \"kajak\"]),\n",
    "  (\"develop\",   10, \"Wilma\",  5200, [\"game\",  \"ski\"]),\n",
    "  (\"develop\",   11, \"Maja\",   5200, [\"game\",  \"farming\"])\n",
    "]).toDF(\"depName\", \"empNo\", \"name\", \"salary\", \"hobby\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+-----------------+\n",
      "|  name|  depName|salary|  mean_dep_salary|\n",
      "+------+---------+------+-----------------+\n",
      "|Astrid|  develop|  4200|           5020.0|\n",
      "|  Saga|  develop|  6000|           5020.0|\n",
      "| Freja|  develop|  4500|           5020.0|\n",
      "| Wilma|  develop|  5200|           5020.0|\n",
      "|  Maja|  develop|  5200|           5020.0|\n",
      "|Olivia|personnel|  3900|           3700.0|\n",
      "| Lilly|personnel|  3500|           3700.0|\n",
      "| Alice|    sales|  5000|4866.666666666667|\n",
      "|  Ella|    sales|  4800|4866.666666666667|\n",
      "|  Ebba|    sales|  4800|4866.666666666667|\n",
      "+------+---------+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ws = Window.partitionBy(F.col('depName'))\n",
    "empsalary.select(F.col('name'), \n",
    "                 F.col('depName'), \n",
    "                 F.col('salary'), \n",
    "                 F.mean(F.col('salary')).over(ws).alias('mean_dep_salary')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wsO9O27WTL5h"
   },
   "source": [
    "Multiples funciones sobre una misma partición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vqlB34R3TL5j",
    "outputId": "6b8b0f87-4dc9-4ae2-d6d6-80bb3644943c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+------+------+------------------------------+--------------+------------+\n",
      "|depName  |empNo|name  |salary|salaries                      |average_salary|total_salary|\n",
      "+---------+-----+------+------+------------------------------+--------------+------------+\n",
      "|develop  |7    |Astrid|4200  |[4200, 6000, 4500, 5200, 5200]|5020          |25100       |\n",
      "|develop  |8    |Saga  |6000  |[4200, 6000, 4500, 5200, 5200]|5020          |25100       |\n",
      "|develop  |9    |Freja |4500  |[4200, 6000, 4500, 5200, 5200]|5020          |25100       |\n",
      "|develop  |10   |Wilma |5200  |[4200, 6000, 4500, 5200, 5200]|5020          |25100       |\n",
      "|develop  |11   |Maja  |5200  |[4200, 6000, 4500, 5200, 5200]|5020          |25100       |\n",
      "|personnel|2    |Olivia|3900  |[3900, 3500]                  |3700          |7400        |\n",
      "|personnel|5    |Lilly |3500  |[3900, 3500]                  |3700          |7400        |\n",
      "|sales    |1    |Alice |5000  |[5000, 4800, 4800]            |4866          |14600       |\n",
      "|sales    |3    |Ella  |4800  |[5000, 4800, 4800]            |4866          |14600       |\n",
      "|sales    |4    |Ebba  |4800  |[5000, 4800, 4800]            |4866          |14600       |\n",
      "+---------+-----+------+------+------------------------------+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "overCategory = Window.partitionBy(\"depName\")\n",
    "df = empsalary\\\n",
    ".withColumn(\"salaries\", collect_list(\"salary\").over(overCategory))\\\n",
    ".withColumn(\"average_salary\", (avg(\"salary\").over(overCategory)).cast(\"int\"))\\\n",
    ".withColumn(\"total_salary\", sum(\"salary\").over(overCategory))\\\n",
    ".select(\"depName\", \"empNo\", \"name\", \"salary\", \n",
    "        \"salaries\", \"average_salary\", \"total_salary\")\n",
    "df.show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JB9Skk0QTL5n"
   },
   "source": [
    "Order by: Default acumulado hasta la fila actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eOY2sjswTL5o",
    "outputId": "e049c934-988e-4548-d06c-d1b643fffeab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+------+------------------------------+-------+-------+-----+-----+-----+\n",
      "|depName  |empNo|salary|salaries                      |msalary|tsalary|ntile|prank|drank|\n",
      "+---------+-----+------+------------------------------+-------+-------+-----+-----+-----+\n",
      "|develop  |7    |4200  |[4200]                        |4200   |4200   |1    |0.0  |1    |\n",
      "|develop  |9    |4500  |[4200, 4500]                  |4350   |8700   |1    |0.25 |2    |\n",
      "|develop  |10   |5200  |[4200, 4500, 5200, 5200]      |4775   |19100  |2    |0.5  |3    |\n",
      "|develop  |11   |5200  |[4200, 4500, 5200, 5200]      |4775   |19100  |2    |0.5  |3    |\n",
      "|develop  |8    |6000  |[4200, 4500, 5200, 5200, 6000]|5020   |25100  |3    |1.0  |4    |\n",
      "|personnel|5    |3500  |[3500]                        |3500   |3500   |1    |0.0  |1    |\n",
      "|personnel|2    |3900  |[3500, 3900]                  |3700   |7400   |2    |1.0  |2    |\n",
      "|sales    |3    |4800  |[4800, 4800]                  |4800   |9600   |1    |0.0  |1    |\n",
      "|sales    |4    |4800  |[4800, 4800]                  |4800   |9600   |2    |0.0  |1    |\n",
      "|sales    |1    |5000  |[4800, 4800, 5000]            |4866   |14600  |3    |1.0  |2    |\n",
      "+---------+-----+------+------------------------------+-------+-------+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "overCategory = Window.partitionBy(\"depName\").orderBy(col(\"salary\").asc())\n",
    "df = empsalary\\\n",
    ".withColumn(\"salaries\", collect_list(\"salary\").over(overCategory))\\\n",
    ".withColumn(\"msalary\", (avg(\"salary\").over(overCategory)).cast(\"int\"))\\\n",
    ".withColumn(\"tsalary\", sum(\"salary\").over(overCategory))\\\n",
    ".withColumn(\"ntile\", ntile(3).over(overCategory))\\\n",
    ".withColumn(\"prank\", F.percent_rank().over(overCategory))\\\n",
    ".withColumn(\"drank\", dense_rank().over(overCategory))\\\n",
    ".select(\"depName\", \"empNo\",  \"salary\", \n",
    "        \"salaries\", \"msalary\", \"tsalary\", \n",
    "        \"ntile\", \"prank\", \"drank\")\n",
    "df.show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yDYkU4d5TL5r"
   },
   "source": [
    "Lag y lead para sacar interacción entre filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D3GM5uPiTL5r",
    "outputId": "745262e1-efa0-4332-b1c7-3b1ae3ae3f56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+------+------+----+----+\n",
      "|depName  |empNo|name  |salary|lead|lag |\n",
      "+---------+-----+------+------+----+----+\n",
      "|develop  |7    |Astrid|4200  |4500|null|\n",
      "|develop  |9    |Freja |4500  |5200|4200|\n",
      "|develop  |10   |Wilma |5200  |5200|4500|\n",
      "|develop  |11   |Maja  |5200  |6000|5200|\n",
      "|develop  |8    |Saga  |6000  |null|5200|\n",
      "|personnel|5    |Lilly |3500  |3900|null|\n",
      "|personnel|2    |Olivia|3900  |null|3500|\n",
      "|sales    |3    |Ella  |4800  |4800|null|\n",
      "|sales    |4    |Ebba  |4800  |5000|4800|\n",
      "|sales    |1    |Alice |5000  |null|4800|\n",
      "+---------+-----+------+------+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import pyspark.sql.functions as F\n",
    "overCategory = Window.partitionBy(\"depName\").orderBy(col(\"salary\").asc())\n",
    "df = empsalary\\\n",
    ".withColumn(\"lead\", F.lead(\"salary\", 1).over(overCategory))\\\n",
    ".withColumn(\"lag\", F.lag(\"salary\", 1).over(overCategory))\\\n",
    ".select(\"depName\", \"empNo\", \"name\", \"salary\", \"lead\", \"lag\")\n",
    "df.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G7mILnbLTL5u",
    "outputId": "7f93e69e-5178-4697-c4b8-42e1d80ab3b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+------+------+----+----+-----+-----+\n",
      "|depName  |empNo|name  |salary|lead|lag |h_t_n|l_t_p|\n",
      "+---------+-----+------+------+----+----+-----+-----+\n",
      "|develop  |8    |Saga  |6000  |5200|null|800  |0    |\n",
      "|develop  |10   |Wilma |5200  |5200|6000|0    |800  |\n",
      "|develop  |11   |Maja  |5200  |4500|5200|700  |0    |\n",
      "|develop  |9    |Freja |4500  |4200|5200|300  |700  |\n",
      "|develop  |7    |Astrid|4200  |null|4500|0    |300  |\n",
      "|personnel|2    |Olivia|3900  |3500|null|400  |0    |\n",
      "|personnel|5    |Lilly |3500  |null|3900|0    |400  |\n",
      "|sales    |1    |Alice |5000  |4800|null|200  |0    |\n",
      "|sales    |3    |Ella  |4800  |4800|5000|0    |200  |\n",
      "|sales    |4    |Ebba  |4800  |null|4800|0    |0    |\n",
      "+---------+-----+------+------+----+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "overCategory = Window.partitionBy(\"depName\").orderBy(col(\"salary\").desc())\n",
    "df = empsalary\\\n",
    ".withColumn(\"lead\", lead(\"salary\", 1).over(overCategory))\\\n",
    ".withColumn(\"lag\", lag(\"salary\", 1).over(overCategory))\\\n",
    ".withColumn(\"h_t_n\", \n",
    "            when(col(\"lead\").isNull(), 0).otherwise(col(\"salary\") - col(\"lead\")))\\\n",
    ".withColumn(\"l_t_p\", \n",
    "            when(col(\"lag\").isNull(), 0).otherwise(col(\"lag\") - col(\"salary\")))\\\n",
    ".select(\"depName\", \"empNo\", \"name\", \"salary\", \"lead\", \"lag\", \"h_t_n\", \"l_t_p\")\n",
    "df.show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "77YsLAkjTL5w"
   },
   "source": [
    "Aplicación de funciones sobre rangos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tBdZxMhJTL5x"
   },
   "outputs": [],
   "source": [
    "overCategory = Window.partitionBy(\"depName\").orderBy(\"salary\")\\\n",
    ".rowsBetween(Window.unboundedPreceding, Window.unboundedFollowing)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "DataFramestransformations.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
